apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm
  labels:
    app: vllm
spec:
  strategy:
    type: Recreate
  replicas: 1
  selector:
    matchLabels:
      app: vllm
  template:
    metadata:
      labels:
        app: vllm
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nvidia.com/gpu.product
                    operator: In
                    values:
                      - NVIDIA-L40S-48C
                      - NVIDIA-L40S-24C
      tolerations:
        - key: "dedicated"
          operator: "Equal"
          value: "gpu"
          effect: "NoSchedule"
      containers:
      - name: vllm-container
        image: vllm/vllm-openai:v0.4.3
        imagePullPolicy: Always
        ports:
          - containerPort: 8000
            name: api
        env:
          - name: HUGGING_FACE_HUB_TOKEN
            value: ""
        args:
          - --enforce-eager
          - --dtype
          - half
          - --model
          - meta-llama/Meta-Llama-3-8B-Instruct
          - --api-key
          - 190E86E1-9B5A-4E79-AF7B-799C24A28E82
        resources:
          limits:
            nvidia.com/gpu: "1"
          requests:
            nvidia.com/gpu: "1"
        volumeMounts:
          - name: vllm-data-volume
            mountPath: /root/.cache
      volumes:
        - name: vllm-data-volume
          persistentVolumeClaim:
            claimName: llm-llm-claim